#!/usr/bin/env python3

import json
import xml.etree.ElementTree as ET
from xml.dom import minidom
import sys
from datetime import datetime

def parse_opml_structure(opml_file):
    """Parse OPML to preserve exact category structure"""
    tree = ET.parse(opml_file)
    root = tree.getroot()
    categories = {}
    
    for outline in root.findall('.//outline'):
        if not outline.get('xmlUrl'):  # This is a category
            category_name = outline.get('title', outline.get('text'))
            if category_name:
                categories[category_name] = []
                for feed_outline in outline.findall('outline[@xmlUrl]'):
                    feed = {
                        'title': feed_outline.get('title', feed_outline.get('text', 'Unknown')),
                        'url': feed_outline.get('htmlUrl', feed_outline.get('xmlUrl')),
                        'feed_url': feed_outline.get('xmlUrl')
                    }
                    categories[category_name].append(feed)
    
    return categories

def load_feeds(jsonl_file, opml_file):
    working_feeds = []
    unprocessed_feeds = []
    excluded_categories = ["다읽기", "뉴스레터", "Instapaper"]
    
    # Get original OPML structure
    original_categories = parse_opml_structure(opml_file)
    
    # Create lookup for processed feeds
    processed_feeds = {}
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                feed = json.loads(line)
                processed_feeds[feed['feed_url']] = feed
                
                # Skip if feed has any excluded categories
                if any(cat in excluded_categories for cat in feed.get('categories', [])):
                    continue
                elif feed['status'] == 'OK' and feed['posts_per_year'] > 0:
                    working_feeds.append(feed)
                else:
                    unprocessed_feeds.append(feed)
    
    print(f"Found {len(working_feeds)} working feeds, {len(unprocessed_feeds)} unprocessed/failed feeds")
    print(f"Original OPML has {len(original_categories)} categories")
    
    return working_feeds, unprocessed_feeds, original_categories, processed_feeds

def calculate_daily_posts(posts_per_year):
    daily = posts_per_year / 365
    return min(daily, 2.0)  # Cap at 2 posts per day

def categorize_feeds(feeds):
    # Sort feeds by frequency
    feeds.sort(key=lambda f: f['posts_per_year'])
    
    categories = []
    current_category = []
    current_daily_total = 0
    category_num = 1
    
    for feed in feeds:
        daily_posts = calculate_daily_posts(feed['posts_per_year'])
        
        if current_daily_total + daily_posts <= 6 and current_category:
            current_category.append(feed)
            current_daily_total += daily_posts
        else:
            if current_category:
                min_freq_monthly = min(f['posts_per_year'] for f in current_category) / 12
                categories.append({
                    'name': f'{category_num:02d}-feeds-{min_freq_monthly:.0f}pm',
                    'feeds': current_category
                })
                category_num += 1
            
            current_category = [feed]
            current_daily_total = daily_posts
    
    if current_category:
        min_freq_monthly = min(f['posts_per_year'] for f in current_category) / 12
        categories.append({
            'name': f'{category_num:02d}-feeds-{min_freq_monthly:.0f}pm',
            'feeds': current_category
        })
    
    return categories

def create_opml(categories, unprocessed_feeds, original_categories, processed_feeds):
    excluded_categories = ["다읽기", "뉴스레터"]
    opml = ET.Element('opml', version='1.0')
    head = ET.SubElement(opml, 'head')
    ET.SubElement(head, 'title').text = 'Feedly Feeds - Categorized'
    ET.SubElement(head, 'dateCreated').text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S %z')
    
    body = ET.SubElement(opml, 'body')
    
    # Add categorized working feeds
    # categorise-feeds.md
    for category in categories:
        outline = ET.SubElement(body, 'outline', text=category['name'], title=category['name'])
        
        for feed in category['feeds']:
            ET.SubElement(outline, 'outline', 
                         type='rss',
                         text=feed['title'],
                         title=feed['title'],
                         xmlUrl=feed['feed_url'],
                         htmlUrl=feed['url'])
    
    # Add unprocessed/failed feeds to a separate category
    if unprocessed_feeds:
        unprocessed_outline = ET.SubElement(body, 'outline', text='99-unprocessed', title='99-unprocessed')
        for feed in unprocessed_feeds:
            ET.SubElement(unprocessed_outline, 'outline',
                         type='rss', 
                         text=feed['title'],
                         title=feed['title'],
                         xmlUrl=feed['feed_url'],
                         htmlUrl=feed['url'])
    
    # Add all original categories (preserving duplicates)
    for category_name, feeds in original_categories.items():
        outline = ET.SubElement(body, 'outline', text=category_name, title=category_name)
        for feed in feeds:
            ET.SubElement(outline, 'outline',
                         type='rss',
                         text=feed['title'], 
                         title=feed['title'],
                         xmlUrl=feed['feed_url'],
                         htmlUrl=feed['url'])
    
    return opml

def main():
    jsonl_file = sys.argv[1] if len(sys.argv) > 1 else 'feedly_feeds.jsonl'
    opml_file = sys.argv[2] if len(sys.argv) > 2 else 'feedly.opml'
    output_file = sys.argv[3] if len(sys.argv) > 3 else 'feedly_categorized.opml'
    
    working_feeds, unprocessed_feeds, original_categories, processed_feeds = load_feeds(jsonl_file, opml_file)
    
    categories = categorize_feeds(working_feeds)
    print(f"Created {len(categories)} categories")
    
    for cat in categories:
        daily_total = sum(calculate_daily_posts(f['posts_per_year']) for f in cat['feeds'])
        print(f"  {cat['name']}: {len(cat['feeds'])} feeds, {daily_total:.1f} posts/day")
    
    if unprocessed_feeds:
        print(f"  99-unprocessed: {len(unprocessed_feeds)} feeds (unprocessed/failed)")
    
    # Show original categories
    total_original_feeds = sum(len(feeds) for feeds in original_categories.values())
    for category, feeds in sorted(original_categories.items()):
        print(f"  {category}: {len(feeds)} feeds (original category)")
    
    opml = create_opml(categories, unprocessed_feeds, original_categories, processed_feeds)
    
    rough_string = ET.tostring(opml, 'unicode')
    reparsed = minidom.parseString(rough_string)
    pretty = reparsed.toprettyxml(indent='  ')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(pretty)
    
    print(f"OPML saved to: {output_file}")
    print(f"Total feeds: {len(working_feeds) + len(unprocessed_feeds) + total_original_feeds}")

if __name__ == '__main__':
    main()
