#!/usr/bin/env python3

import json
import xml.etree.ElementTree as ET
from xml.dom import minidom
import sys
from datetime import datetime

def parse_opml_excluded_feeds(opml_file):
    """Parse OPML to get feeds from excluded categories"""
    tree = ET.parse(opml_file)
    root = tree.getroot()
    parent_map = {c: p for p in tree.iter() for c in p}
    excluded_categories = ["다읽기", "뉴스레터"]
    excluded_feeds = []
    
    for outline in root.findall('.//outline'):
        xml_url = outline.get('xmlUrl')
        if xml_url:
            current = outline
            categories = []
            while current in parent_map:
                parent = parent_map[current]
                if parent.tag == 'outline' and not parent.get('xmlUrl'):
                    category_name = parent.get('title', parent.get('text'))
                    if category_name:
                        categories.insert(0, category_name)
                current = parent
            
            if any(cat in excluded_categories for cat in categories):
                feed = {
                    'title': outline.get('title', outline.get('text', 'Unknown')),
                    'url': outline.get('htmlUrl', xml_url),
                    'feed_url': xml_url,
                    'categories': categories
                }
                excluded_feeds.append(feed)
    
    return excluded_feeds

def load_feeds(jsonl_file, opml_file):
    working_feeds = []
    unprocessed_feeds = []
    excluded_categories = ["다읽기", "뉴스레터"]
    
    # Get excluded feeds from original OPML
    excluded_feeds = parse_opml_excluded_feeds(opml_file)
    
    # Load processed feeds from JSONL, excluding those in excluded categories
    with open(jsonl_file, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                feed = json.loads(line)
                
                # Skip if feed has any excluded categories (already handled above)
                if any(cat in excluded_categories for cat in feed.get('categories', [])):
                    continue
                elif feed['status'] == 'OK' and feed['posts_per_year'] > 0:
                    working_feeds.append(feed)
                else:
                    unprocessed_feeds.append(feed)
    
    print(f"Found {len(working_feeds)} working feeds, {len(unprocessed_feeds)} unprocessed/failed feeds")
    print(f"Excluded {len(excluded_feeds)} feeds from categories: {', '.join(excluded_categories)} (all feeds from original OPML preserved)")
    
    return working_feeds, unprocessed_feeds, excluded_feeds

def calculate_daily_posts(posts_per_year):
    daily = posts_per_year / 365
    return min(daily, 2.0)  # Cap at 2 posts per day

def categorize_feeds(feeds):
    # Sort feeds by frequency
    feeds.sort(key=lambda f: f['posts_per_year'])
    
    categories = []
    current_category = []
    current_daily_total = 0
    category_num = 1
    
    for feed in feeds:
        daily_posts = calculate_daily_posts(feed['posts_per_year'])
        
        if current_daily_total + daily_posts <= 6 and current_category:
            current_category.append(feed)
            current_daily_total += daily_posts
        else:
            if current_category:
                min_freq = min(f['posts_per_year'] for f in current_category)
                categories.append({
                    'name': f'{category_num:02d}-feeds-{min_freq}py',
                    'feeds': current_category
                })
                category_num += 1
            
            current_category = [feed]
            current_daily_total = daily_posts
    
    if current_category:
        min_freq = min(f['posts_per_year'] for f in current_category)
        categories.append({
            'name': f'{category_num:02d}-feeds-{min_freq}py',
            'feeds': current_category
        })
    
    return categories

def create_opml(categories, unprocessed_feeds, excluded_feeds):
    opml = ET.Element('opml', version='1.0')
    head = ET.SubElement(opml, 'head')
    ET.SubElement(head, 'title').text = 'Feedly Feeds - Categorized'
    ET.SubElement(head, 'dateCreated').text = datetime.now().strftime('%a, %d %b %Y %H:%M:%S %z')
    
    body = ET.SubElement(opml, 'body')
    
    # Add categorized working feeds
    for category in categories:
        outline = ET.SubElement(body, 'outline', text=category['name'], title=category['name'])
        
        for feed in category['feeds']:
            ET.SubElement(outline, 'outline', 
                         type='rss',
                         text=feed['title'],
                         title=feed['title'],
                         xmlUrl=feed['feed_url'],
                         htmlUrl=feed['url'])
    
    # Add unprocessed/failed feeds to a separate category
    if unprocessed_feeds:
        unprocessed_outline = ET.SubElement(body, 'outline', text='99-unprocessed', title='99-unprocessed')
        for feed in unprocessed_feeds:
            ET.SubElement(unprocessed_outline, 'outline',
                         type='rss', 
                         text=feed['title'],
                         title=feed['title'],
                         xmlUrl=feed['feed_url'],
                         htmlUrl=feed['url'])
    
    # Add excluded feeds in their original categories
    excluded_by_category = {}
    for feed in excluded_feeds:
        for category in feed['categories']:
            if category not in excluded_by_category:
                excluded_by_category[category] = []
            excluded_by_category[category].append(feed)
    
    for category_name, feeds in excluded_by_category.items():
        outline = ET.SubElement(body, 'outline', text=category_name, title=category_name)
        for feed in feeds:
            ET.SubElement(outline, 'outline',
                         type='rss',
                         text=feed['title'], 
                         title=feed['title'],
                         xmlUrl=feed['feed_url'],
                         htmlUrl=feed['url'])
    
    return opml

def main():
    jsonl_file = sys.argv[1] if len(sys.argv) > 1 else 'feedly_feeds.jsonl'
    opml_file = sys.argv[2] if len(sys.argv) > 2 else 'feedly.opml'
    output_file = sys.argv[3] if len(sys.argv) > 3 else 'feedly_categorized.opml'
    
    working_feeds, unprocessed_feeds, excluded_feeds = load_feeds(jsonl_file, opml_file)
    
    categories = categorize_feeds(working_feeds)
    print(f"Created {len(categories)} categories")
    
    for cat in categories:
        daily_total = sum(calculate_daily_posts(f['posts_per_year']) for f in cat['feeds'])
        print(f"  {cat['name']}: {len(cat['feeds'])} feeds, {daily_total:.1f} posts/day")
    
    if unprocessed_feeds:
        print(f"  99-unprocessed: {len(unprocessed_feeds)} feeds (unprocessed/failed)")
    
    if excluded_feeds:
        excluded_by_category = {}
        for feed in excluded_feeds:
            for category in feed['categories']:
                excluded_by_category[category] = excluded_by_category.get(category, 0) + 1
        for category, count in excluded_by_category.items():
            print(f"  {category}: {count} feeds (original category)")
    
    opml = create_opml(categories, unprocessed_feeds, excluded_feeds)
    
    rough_string = ET.tostring(opml, 'unicode')
    reparsed = minidom.parseString(rough_string)
    pretty = reparsed.toprettyxml(indent='  ')
    
    with open(output_file, 'w', encoding='utf-8') as f:
        f.write(pretty)
    
    print(f"OPML saved to: {output_file}")
    print(f"Total feeds: {len(working_feeds) + len(unprocessed_feeds) + len(excluded_feeds)}")

if __name__ == '__main__':
    main()
